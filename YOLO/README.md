# üö¥‚Äç‚ôÇÔ∏è YOLOv8 Training & Validation Pipeline

This directory contains the complete toolkit for processing synthetic data generated by Isaac Sim, training a **YOLOv8** object detector, and auditing results through visual reports.

## üìÇ Directory Content

- `dataset_manager.py`: ETL (Extract, Transform, Load). Converts labels from KITTI format to YOLO, manages folder structure (`train/val/test`), and allows adding data incrementally.

- `train_YOLO.py`: Training script. Automatically configures the environment for YOLOv8 and exports the final model to ONNX.

- `visualize_results.py`: Audit and testing tool. Generates interactive HTML reports, confusion matrices, and prediction visualizations.

- `report_utils.py`: Auxiliary library for mathematical calculations (IoU, metrics) and graph generation.

## ‚öôÔ∏è Installation

This pipeline requires specific Computer Vision and Data Science libraries. Install them with:

```bash
pip install ultralytics opencv-python matplotlib seaborn pandas pyyaml
```

Note: It is recommended to use a virtual environment or Conda to avoid interfering with the Isaac Sim environment if running on the same machine.

## üöÄ Workflow

### Step 1: Dataset Management (dataset_manager.py)

This script automatically looks for data generated in the `../_output_data/` folder of the main repository.

### Options:

1. **Create Dataset from scratch (Reset):** Deletes any previous dataset and creates a clean structure.

```bash
python dataset_manager.py
```

2. **Incremental Mode (Append):** Useful if you have generated a new batch of images in Isaac Sim and want to add them to your training dataset without deleting what you already had. Renames files with a timestamp to avoid duplicates.

```bash
python dataset_manager.py --append
```

### Step 2: Training (train_YOLO.py)

Downloads the pre-trained model (YOLOv8 Small by default) and performs fine-tuning with your data.

### Execution Options:

1. **Standard Training (Automatic):** Uses the default configuration (YOLOv8 Small, 50 epochs).

```bash
python train_YOLO.py
```

2. **Customize Duration:** Overrides the number of epochs without changing the rest of the configuration.

```bash
python train_YOLO.py --epochs 100
```

3. **Interactive Mode (Model Selection):** Opens a console assistant to choose the YOLO version (v8 or v11), model size (Nano, Small, Medium), and experiment name.

```bash
python train_YOLO.py --select
```

### Step 3: Audit and Visualization (visualize_results.py)

Once the model is trained, use this tool to understand what is happening.

#### üïµÔ∏è **Audit Mode (Test Dataset)**

Analyzes images from the test set (which have real labels) and compares them with the AI's prediction.

- **See only errors:** Generates separate folders for False Negatives (missed) and False Positives (invented).

```bash
python visualize_results.py
```

- **See all (Full Report):** Generates images with Green boxes (Ground Truth) and Blue boxes (AI + Confidence). Creates an HTML report with a heatmap and metrics.

```bash
python visualize_results.py --draw_all
```

#### üåç **Inference Mode (Real World)**

Test your model with new photos that do not have labels (e.g., real camera photos).

```bash
python visualize_results.py --source /path/to/my/real_photos
```

#### üé• **Video Mode**

Processes an MP4 video and generates an output video with detections.

```bash
python visualize_results.py --video assets/test_video.mp4
```

## üìä The HTML Report (audit_report/)

If you run the audit mode, an `audit_report` folder will be generated. Open the `report.html` file in your browser to see:

- **Precision/Recall/F1:** Industrial quality metrics.

- **Heatmap:** Does your model detect only in the center of the image or does it cover the edges well?

- **Confidence Histogram:** Is the model too confident in its errors?